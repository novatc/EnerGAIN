
@inproceedings{wang_energy_2018,
	title = {Energy {Storage} {Arbitrage} in {Real}-{Time} {Markets} via {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1711.03127},
	doi = {10.1109/PESGM.2018.8586321},
	abstract = {In this paper, we derive a temporal arbitrage policy for storage via reinforcement learning. Real-time price arbitrage is an important source of revenue for storage units, but designing good strategies have proven to be difficult because of the highly uncertain nature of the prices. Instead of current model predictive or dynamic programming approaches, we use reinforcement learning to design an optimal arbitrage policy. This policy is learned through repeated charge and discharge actions performed by the storage unit through updating a value matrix. We design a reward function that does not only reflect the instant profit of charge/discharge decisions but also incorporate the history information. Simulation results demonstrate that our designed reward function leads to significant performance improvement compared with existing algorithms.},
	urldate = {2023-06-07},
	booktitle = {2018 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting} ({PESGM})},
	author = {Wang, Hao and Zhang, Baosen},
	month = aug,
	year = {2018},
	note = {arXiv:1711.03127 [cs, math]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Systems and Control, Mathematics - Optimization and Control},
	pages = {1--5},
}

@article{schimeczek_amiris_2023,
	title = {{AMIRIS}: {Agent}-based {Market} model for the {Investigationof} {Renewable} and {Integrated} energy {Systems}},
	volume = {8},
	issn = {2475-9066},
	shorttitle = {{AMIRIS}},
	url = {https://joss.theoj.org/papers/10.21105/joss.05041},
	doi = {10.21105/joss.05041},
	number = {84},
	urldate = {2023-06-05},
	journal = {Journal of Open Source Software},
	author = {Schimeczek, Christoph and Nienhaus, Kristina and Frey, Ulrich and Sperber, Evelyn and Sarfarazi, Seyedfarzad and Nitsch, Felix and Kochems, Johannes and Ghazi, A. Achraf El},
	month = apr,
	year = {2023},
	pages = {5041},
}

@book{sutton_reinforcement_2018,
	address = {Cambridge, Massachusetts},
	edition = {Second edition},
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning: an introduction},
	isbn = {978-0-262-03924-6},
	shorttitle = {Reinforcement learning},
	abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
	language = {en},
	publisher = {The MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {2018},
	keywords = {Reinforcement learning},
}

@book{sutton_reinforcement_2018-1,
	address = {Cambridge, Massachusetts},
	edition = {Second edition},
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning: an introduction},
	isbn = {978-0-262-03924-6},
	shorttitle = {Reinforcement learning},
	abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
	publisher = {The MIT Press},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {2018},
	keywords = {Reinforcement learning},
}

@article{grasl_evaluating_2014,
	title = {Evaluating {Measures} for {Adapting} the {Energy} {Demand} of a {Production} {System} to {Volatile} {Energy} {Prices}},
	volume = {15},
	issn = {2212-8271},
	url = {https://www.sciencedirect.com/science/article/pii/S2212827114005046},
	doi = {https://doi.org/10.1016/j.procir.2014.06.081},
	abstract = {Due to the increasing use of renewable energies and the volatile behaviour of wind and sun power new turbulences in energy markets – especially increasing and strongly fluctuating energy prices – are expected. Hence, companies’ production systems have to be energy flexible in order to cope with these changes in energy markets. This paper presents an approach for evaluating measures for conducting energy flexibility, e.g. changing process parameters or rescheduling of processes depending on the availability of energy in the grid.},
	journal = {Procedia CIRP},
	author = {Graßl, Markus and Reinhart, Gunther},
	year = {2014},
	keywords = {Energy flexibility, demand response, energy efficiency, flexibility evaluation, renewable energies},
	pages = {129--134},
}

@article{wu_optimal_2022,
	title = {Optimal {Battery} {Sizing} for {Frequency} {Regulation} and {Energy} {Arbitrage}},
	volume = {37},
	doi = {10.1109/TPWRD.2021.3102420},
	number = {3},
	journal = {IEEE Transactions on Power Delivery},
	author = {Wu, Xuan and Zhao, Jenny and Conejo, Antonio J.},
	year = {2022},
	pages = {2016--2023},
}

@article{tesauro_temporal_1995,
	title = {Temporal difference learning and {TD}-{Gammon}},
	volume = {38},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/203330.203343},
	doi = {10.1145/203330.203343},
	abstract = {Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.},
	language = {en},
	number = {3},
	urldate = {2023-05-30},
	journal = {Communications of the ACM},
	author = {Tesauro, Gerald},
	month = mar,
	year = {1995},
	pages = {58--68},
}

@misc{noauthor_strom_2023,
	title = {Strom, {Wärme}, {Sektorkopplung} - {energyPRO} {AnwendungsfelderEMD} {International}},
	url = {https://www.emd-international.com/de/energypro/themen/},
	abstract = {Modellierung mit Strom, Wärme oder Sektorkopplung. Erfahren Sie mehr über typische Anwendungsfelder von energyPRO},
	language = {de-DE},
	urldate = {2023-05-29},
	month = jan,
	year = {2023},
}

@misc{noauthor_smard_nodate,
	title = {{SMARD} {\textbar} {Marktdaten}},
	url = {https://www.smard.de/home/downloadcenter/download-marktdaten/},
	urldate = {2023-05-29},
}

@misc{noauthor_smard_nodate-1,
	title = {{SMARD} {\textbar} {Alle} {Artikel}},
	url = {https://www.smard.de/home/strommarkt-aktuell/strommarkt-aktuell},
	urldate = {2023-05-29},
}

@misc{noauthor_bundesnetzagentur_nodate,
	title = {Bundesnetzagentur - {Presse} - {Bundesnetzagentur} ändert {Zuschlagmechanismus} bei {Ausschreibung} von {Regelenergie}},
	url = {https://www.bundesnetzagentur.de/SharedDocs/Pressemitteilungen/DE/2018/20180516_Regelenergie.html},
	urldate = {2023-05-29},
}

@article{dong_strategic_2021,
	title = {A {Strategic} {Day}-ahead bidding strategy and operation for battery energy storage system by reinforcement learning},
	volume = {196},
	issn = {0378-7796},
	url = {https://www.sciencedirect.com/science/article/pii/S0378779621002108},
	doi = {https://doi.org/10.1016/j.epsr.2021.107229},
	abstract = {The Battery Energy Storage System (BESS) plays an essential role in the smart grid, and the ancillary market offers a high revenue. It is important for BESS owners to maximise their profit by deciding how to balance between the different offers and bidding with the rivals. Therefore, this paper formulates the BESS bidding problem as a Markov Decision Process(MDP) to maximise the total profit from the e Automation Generation Control (AGC) market and the energy market, considering the factors such as charging/discharging losses and the lifetime of the BESS. In the proposed algorithm, function approximation technology is introduced to handle the continuous massive bidding scales and avoid the dimension curse. As a model-free approach, the proposed algorithm can learn from the stochastic and dynamic environment of a power market, so as to help the BESS owners to decide their bidding and operational schedules profitably. Several case studies illustrate the effectiveness and validity of the proposed algorithm.},
	journal = {Electric Power Systems Research},
	author = {Dong, Yi and Dong, Zhen and Zhao, Tianqiao and Ding, Zhengtao},
	year = {2021},
	keywords = {Battery energy storage system (BESS), Power market bidding, Reinforcement learning},
	pages = {107229},
}

@article{nitsch_economic_2021,
	title = {Economic evaluation of battery storage systems bidding on day-ahead and automatic frequency restoration reserves markets},
	volume = {298},
	issn = {0306-2619},
	url = {https://www.sciencedirect.com/science/article/pii/S0306261921006851},
	doi = {https://doi.org/10.1016/j.apenergy.2021.117267},
	abstract = {In future electricity systems, not only electricity generation but also frequency stabilization must be provided by low-carbon technologies. Battery systems are a promising solution to fill this gap. However, uncertainties regarding their revenue potential may hinder investments. Therefore, we apply the agent-based electricity market model AMIRIS to simulate a day-ahead market and an automatic frequency restoration reserves market. Demonstrating the model setup, we chose a scenario with high shares of renewable energies. First, we back-test our model with historic market data from Germany in 2019. The simulation results’ mean day-ahead prices of 39.20EUR/MWh are close to the historic ones of 38.70EUR/MWh. Second, we model both markets in a scenario for 2030. The simulated day-ahead market prices are higher on average than observed today, although, we find around 550 h/yr in which the load is fully covered by renewable energies. The variance in simulated prices is slightly higher compared to historic values. Bids on the reserve capacity market are derived from opportunity costs of not participating in the day-ahead market. This results in prices of up to 45EUR/MW for positive reserve while the prices for negative reserve are 0EUR/MW. Finally, we evaluate revenue potentials of battery storages. Compared to 2019, we see an improved economic potential and increased importance of the day-ahead market. High power battery storages perform best whereas improvements in round-trip efficiency only marginally improve revenues. Although demonstrated for Germany, the presented modular approach can be adapted to international markets enabling comprehensive battery storage assessments.},
	journal = {Applied Energy},
	author = {Nitsch, Felix and Deissenroth-Uhrig, Marc and Schimeczek, Christoph and Bertsch, Valentin},
	year = {2021},
	keywords = {Agent-based modeling, Automatic Frequency Restoration Reserves market, Battery storage system, Day-ahead market, Energy system modeling},
	pages = {117267},
}

@article{han_deep-learning-_2021,
	title = {Deep-learning- and reinforcement-learning-based profitable strategy of a grid-level energy storage system for the smart grid},
	volume = {41},
	issn = {2352-152X},
	url = {https://www.sciencedirect.com/science/article/pii/S2352152X21005909},
	doi = {https://doi.org/10.1016/j.est.2021.102868},
	abstract = {A profitable operation strategy of an energy storage system (ESS) could play a pivotal role in the smart grid, balancing electricity supply with demand. Here, we propose an AI-based novel arbitrage strategy to maximize operating profit in the electricity market composed of a grid operator (GO), an ESS, and customers (CUs). This strategy, the buying and selling of electricity to profit from a price imbalance, can also cause a peak load shift from on-peak to off-peak, a win-win approach for both the ESS operator (EO) and the GO. Particularly, to maximize the EO's profit and further reduce the GO's on-peak power, we introduce a stimulus-integrated arbitrage algorithm, providing an additional reward to the EO from the GO with different weights for each peak period. The algorithm consists of two parts: the first is recurrent neural network-based deep learning for overcoming the future uncertainties of electricity prices and load demands. The second is reinforcement learning to derive the optimal charging or discharging policy considering the grid peak states, the EO's profit, and CUs’ load demand. We find it significant that the suggested approach increases operating profit 2.4 times and decreases the on-peak power of the GO by 30\%.},
	journal = {Journal of Energy Storage},
	author = {Han, Gwangwoo and Lee, Sanghun and Lee, Jaemyung and Lee, Kangyong and Bae, Joongmyeon},
	year = {2021},
	keywords = {AI, Deep learning, Energy storage system, Recurrent neural network, Reinforcement learning, Smart grid},
	pages = {102868},
}

@inproceedings{denholm_role_2010,
	title = {Role of {Energy} {Storage} with {Renewable} {Electricity} {Generation}},
	author = {Denholm, Paul L. and Ela, Erik and Kirby, Brendan and Milligan, Michael R.},
	year = {2010},
}

@misc{rocca_exploration-exploitation_2021,
	title = {The exploration-exploitation trade-off: intuitions and strategies},
	shorttitle = {The exploration-exploitation trade-off},
	url = {https://towardsdatascience.com/the-exploration-exploitation-dilemma-f5622fbe1e82},
	abstract = {Understanding e-greedy, optimistic initialisation, UCB and Thompson sampling strategies},
	language = {en},
	urldate = {2023-05-29},
	journal = {Medium},
	author = {Rocca, Joseph},
	month = may,
	year = {2021},
}

@misc{noauthor_bundesnetzagentur_nodate-1,
	title = {Bundesnetzagentur - {Regelenergie}},
	url = {https://www.bundesnetzagentur.de/DE/Fachthemen/ElektrizitaetundGas/Versorgungssicherheit/Netzengpassmanagement/Engpassmanagement/Regelenergie/start.html},
	urldate = {2023-05-29},
}

@misc{noauthor_day-ahead-handel_nodate,
	title = {Day-{Ahead}-{Handel} - was ist das?},
	url = {https://www.next-kraftwerke.de/wissen/day-ahead-handel},
	abstract = {Day-Ahead-Handel ist der Handel von Strom für den folgenden Tag an der European Power Exchange (EPEX SPOT). Doch wie hat sich dieser Strommarkt etabliert und wie funktioniert der Handel day ahead konkret? Hier finden Sie Antworten.},
	urldate = {2023-05-29},
}

@article{watkins_q-learning_1992,
	title = {Q-learning},
	volume = {8},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00992698},
	doi = {10.1007/BF00992698},
	abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
	number = {3},
	journal = {Machine Learning},
	author = {Watkins, Christopher J. C. H. and Dayan, Peter},
	month = may,
	year = {1992},
	pages = {279--292},
}

@book{hasche_integration_2016,
	title = {Die {Integration} von {Batteriespeichern} am {Regelleistungsmarkt} - eine modellgestützte {Bewertung} {50Hertz} {Schlussbericht} : {Verbundvorhaben} {SDL}-{Batt}: {Systemdienstleistungen} und {Energiespeicherung} mittels {Großbatterien} zur {Stabilisierung} von {Netzen} mit hohen {EE}-{Anteilen} - {Konzeption} und {Demonstration}; {Teilvorhaben}: {Netz}- und {Marktintegration} des innovativen 10 {MW} {Batteriesystem} : {Laufzeit}: 01.03.2013-29.02.2016},
	url = {https://doi.org/10.2314/GBV:872471306},
	publisher = {50Hertz Transmission GmbH},
	author = {Hasche, Bernhard},
	editor = {Haiges, Maik and Schulz, Stephan and GmbH, 50Hertz Transmission},
	year = {2016},
}

@article{dayan_reinforcement_2008,
	title = {Reinforcement learning: {The} {Good}, {The} {Bad} and {The} {Ugly}},
	volume = {18},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438808000767},
	doi = {https://doi.org/10.1016/j.conb.2008.08.003},
	abstract = {Reinforcement learning provides both qualitative and quantitative frameworks for understanding and modeling adaptive decision-making in the face of rewards and punishments. Here we review the latest dispatches from the forefront of this field, and map out some of the territories where lie monsters.},
	number = {2},
	journal = {Current Opinion in Neurobiology},
	author = {Dayan, Peter and Niv, Yael},
	year = {2008},
	pages = {185--196},
}

@misc{noauthor_global_nodate,
	title = {Global {EV} {Outlook} 2020 – {Analysis}},
	url = {https://www.iea.org/reports/global-ev-outlook-2020},
	abstract = {Global EV Outlook 2020 - Analysis and key findings. A report by the International Energy Agency.},
	language = {en-GB},
	urldate = {2023-05-29},
	journal = {IEA},
}

@article{leonard_substitution_2018,
	title = {Substitution of coal power plants with renewable energy sources – {Shift} of the power demand and energy storage},
	volume = {164},
	issn = {0196-8904},
	url = {https://www.sciencedirect.com/science/article/pii/S0196890418302000},
	doi = {10.1016/j.enconman.2018.02.083},
	abstract = {Because of their Global Climate Change contributions, it is desirable to reduce the amount of the global CO2 emissions. One of the ways to accomplish this is the substitution of coal with renewable energy sources, most notably wind and solar. However, the availability of wind energy and of insolation does not follow the diurnal and annual demand patterns of electric power. The large-scale substitution of coal with wind and solar significantly shifts the demand for the rest of the power producing units. When the contribution of wind and solar exceeds approximately 25\% of the total annual energy produced, there are time periods within a year when excess electricity is produced that must be wasted/dissipated. This presents a severe constraint for the substitution of coal-generated electricity with renewables. At such production levels diurnal or seasonal storage of energy becomes necessary and hydrogen storage offers the best alternative. Based on the hourly, electricity demand of a region in North Texas, which has very high availability of wind and solar energy and is considered prime region for renewables, extensive calculations are made for: (a) the solar and wind rated power that are necessary for the substitution of part or all the power currently supplied by a coal-fired power plant; and (b) the storage requirements for this substitution. Significant seasonal and diurnal energy storage, on the order of 250,000 m3, is required for the total substitution of coal in the region. The calculations also reveal that the substitution of coal with the renewable energy sources may be optimized for minimum energy storage capacity.},
	language = {en},
	urldate = {2023-05-25},
	journal = {Energy Conversion and Management},
	author = {Leonard, Matthew D. and Michaelides, Efstathios E. and Michaelides, Dimitrios N.},
	month = may,
	year = {2018},
	keywords = {Coal substitution, Electricity demand and supply, Energy storage, Renewable energy, Solar energy, Wind energy},
	pages = {27--35},
}

@misc{noauthor_renewable_nodate,
	title = {Renewable {Capacity} {Statistics} 2021},
	url = {https://www.irena.org/publications/2021/March/Renewable-Capacity-Statistics-2021},
	urldate = {2023-05-25},
}
